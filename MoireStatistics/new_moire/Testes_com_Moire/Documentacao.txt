Documentação resumida do seu primeiro script. É utilizado para preparar as imagens para o aprendizado de uma rede neural:

### Descrição Geral do Script
Este script é responsável por processar um conjunto de imagens para treinamento ou teste de um modelo de rede neural.
Ele ajusta o tamanho das imagens, converte para escala de cinza, aplica transformações (rotação e espelhamento) e utiliza a
Transformada Wavelet de Haar 2D para decompor as imagens em componentes de frequência. As imagens processadas são então normalizadas
e salvas para uso posterior pela rede neural.

### Funções Principais
1. **`process_image(args)`**:
   - **Parâmetros**: Recebe uma tupla contendo o nome do arquivo, o diretório principal e o diretório de treinamento.
   - **Finalidade**: Processa uma única imagem, aplicando redimensionamento,
		             conversão para escala de cinza, e transformações opcionais. Utiliza a função 
		             `transformImageAndSave` para transformar a imagem com a Transformada de Haar e salvar os componentes resultantes.
   - **Retorno**: Número de imagens processadas com sucesso.

2. **`normalize_and_convert_image(component)`**:
   - **Parâmetros**: Componente da imagem a ser normalizado.
   - **Finalidade**: Normaliza o componente da imagem entre 0 e 255 e o converte para um objeto de imagem PIL.
   - **Retorno**: Imagem PIL normalizada.

3. **`transformImageAndSave(image, f, customStr, path)`**:
   - **Parâmetros**: Imagem a ser transformada, nome do arquivo original, string personalizada para nomenclatura e caminho do diretório de destino.
   - **Finalidade**: Aplica a Transformada de Haar 2D, normaliza cada componente resultante e salva cada um como um arquivo TIFF.
   - **Retorno**: Booleano indicando sucesso ou falha no salvamento das imagens.

4. **`createTrainingData(imagePath, trainFolderPath)`**:
   - **Parâmetros**: Caminho do diretório das imagens e caminho do diretório de destino.
   - **Finalidade**: Processa todas as imagens em um diretório, utilizando multiprocessing
		             para acelerar o processo. Registra o uso da CPU e progresso com barras de progresso.
   - **Retorno**: Soma total das imagens processadas com sucesso.

5. **`main(args)`**:
   - **Parâmetros**: Argumentos da linha de comando que especificam os diretórios de imagens positivas e negativas,
		             e se o processamento é para treinamento ou teste.
   - **Finalidade**: Gerencia o fluxo principal de execução do script, processando dados de treino ou teste conforme especificado.

6. **`parse_arguments(argv)`**:
   - **Finalidade**: Parseia os argumentos da linha de comando.
   - **Retorno**: Objeto com as opções configuradas.

### Configurações Adicionais
- **Logging**: Configurado para registrar tanto em arquivo quanto no console, com detalhes sobre o progresso e erros.
- **Multiprocessing**: Utilizado para paralelizar o processamento de imagens e melhorar a eficiência.

### Dependências Externas
- **Bibliotecas**: `sys`, `argparse`, `os`, `numpy`, `PIL`, `multiprocessing`, `logging`, `tqdm`, `psutil`.
- **Funções externas**: `fwdHaarDWT2D_pywt` do módulo `haar2D`.

##########################################################################################################################

Aqui está a documentação para o script `haar2D.py`, que contém uma função essencial para a transformação de imagens utilizada no pipeline:

### Descrição Geral do Script
Este script fornece uma função para aplicar a Transformada de Haar 2D em imagens. 
A Transformada de Haar é utilizada para decompor uma imagem em componentes de frequência variável,
o que é útil em várias aplicações de processamento de imagem, incluindo compressão e análise de textura.

### Funções Principais
1. **`fwdHaarDWT2D_pywt(img)`**:
   - **Parâmetros**: Uma imagem em formato de array numpy.
   - **Finalidade**: Converter a imagem de entrada para um formato de ponto 
					 flutuante, aplicar a Transformada de Haar 2D usando a biblioteca PyWavelets e retornar os coeficientes decompostos.
					 Os coeficientes são retornados na ordem: LL (aproximação de baixa frequência), LH (detalhes horizontais), HL (detalhes verticais)
		             e HH (detalhes diagonais).
   - **Retorno**: Tupla contendo os componentes da imagem decomposta: `cA` (componente de aproximação), `cH` (componente horizontal),
				  `cV` (componente vertical), e `cD` (componente diagonal).

### Dependências Externas
- **Bibliotecas**: `numpy` e `pywt` (PyWavelets).


Este script é essencial para o funcionamento do primeiro script ,
pois fornece a funcionalidade necessária para decompor as imagens em componentes de frequência
antes de serem normalizadas e salvas para uso posterior pelo modelo de rede neural.


################################################################################################################

Aqui está a documentação para o script de treinamento da rede neural, que é responsável por treinar o modelo de CNN multi-entrada
para detectar padrões de moiré em imagens:

### Descrição Geral do Script
Este script treina um modelo de Rede Neural Convolucional (CNN) usando dados de imagens processados por decomposição wavelet.
O modelo utiliza imagens da componente de baixa frequência (LL) da transformada wavelet como um parâmetro de peso, ajudando na detecção
e localização espacial dos padrões de moiré em contraste com as texturas de alta frequência do fundo.

### Funções Principais
1. **`main(args)`**:
   - **Parâmetros**: Argumentos da linha de comando especificando diretórios de imagens positivas e negativas, e número de épocas de treinamento.
   - **Finalidade**: Coordena as funções de leitura de dados, divisão de treino/teste, treinamento do modelo e avaliação.
   
2. **`readAndScaleImage(...)`**:
   - **Finalidade**: Lê e escala uma única imagem de um conjunto de treinamento, 
					 transformando-a de acordo com especificações e armazenando em matrizes para treinamento.
   
3. **`readImageSet(...)`**:
   - **Finalidade**: Lê um conjunto completo de imagens de uma classe, aplicando transformações padrão e adicionais para aumentar os dados.
   
4. **`readWaveletData(...)`**:
   - **Finalidade**: Lê e processa todos os dados de imagem dos diretórios de treinamento, balanceando as classes positivas e negativas.
   
5. **`trainTestSplit(...)`**:
   - **Finalidade**: Divide os dados em conjuntos de treinamento e teste, mantendo a estratificação das classes.
   
6. **`trainCNNModel(...)`**:
   - **Finalidade**: Configura e treina o modelo de CNN, utilizando uma estratégia de múltiplas GPUs para acelerar o treinamento.
   
7. **`evaluate(...)`**:
   - **Finalidade**: Avalia o modelo treinado usando o conjunto de teste, calculando métricas como precisão, revocação e acurácia.

### Configurações Adicionais
- **ModelCheckpoint**: Utilizado para salvar o modelo no melhor estado durante o treinamento.
- **Estratégia de Múltiplas GPUs**: Utiliza a `tf.distribute.MirroredStrategy` para permitir o treinamento distribuído em várias GPUs.

### Dependências Externas
- **Bibliotecas**: `tensorflow`, `numpy`, `matplotlib`, `PIL`, `sklearn`, `os`, `sys`, `argparse`.
- **Funções externas**: O script depende do módulo `mCNN` para a criação do modelo, que não foi fornecido.

##################################################################################################

Aqui está a documentação para o script que contém o modelo ou arquitetura da rede neural utilizada no pipeline:

### Descrição Geral do Script
Este script define a arquitetura de um modelo de Rede Neural Convolucional (CNN) multi-entrada. O modelo é especialmente projetado para trabalhar com imagens decompostas usando transformação wavelet. Utiliza múltiplas entradas correspondentes a diferentes componentes da transformada wavelet (LL, LH, HL, HH) e aplica uma série de operações de convolução, normalização, agrupamento e ativação para processar esses dados. A arquitetura destina-se a detectar e localizar padrões de moiré nas imagens.

### Funções Principais
1. **`conv_block(inp, depth, kernel_size, pool_size, initializer)`**:
   - **Parâmetros**: Camada de entrada, profundidade da convolução, tamanho do kernel, tamanho da piscina, inicializador.
   - **Finalidade**: Cria um bloco de convolução que inclui convolução, normalização em lote e agrupamento máximo.
   - **Retorno**: Camada de saída após o agrupamento.

2. **`createModel(height, width, depth, num_classes)`**:
   - **Parâmetros**: Altura, largura e profundidade das imagens de entrada, número de classes para classificação.
   - **Finalidade**: Constrói o modelo completo de CNN utilizando a função `conv_block` para tratar cada componente da transformada wavelet de entrada, combina essas entradas e finaliza com uma série de camadas convolucionais e de agrupamento antes de passar para uma camada totalmente conectada e uma camada de saída.
   - **Retorno**: Modelo Keras configurado e pronto para ser compilado e treinado.

### Componentes da Rede
- **Entradas**: Quatro entradas separadas para cada componente da transformada wavelet (LL, LH, HL, HH).
- **Blocos de Convolução**: Aplicados individualmente a cada entrada para extrair características.
- **Fusão e Multiplicação**: As saídas dos blocos são combinadas usando operações de máximo e multiplicação para integrar informações de diferentes componentes.
- **Camadas Adicionais**: Várias camadas convolucionais adicionais são aplicadas após a fusão, seguidas por agrupamento e dropout para regularização.
- **Camada Densa**: Uma camada totalmente conectada segue a planificação dos mapas de características.
- **Saída**: Uma única unidade com ativação sigmoidal, adequada para tarefas de classificação binária.

### Configurações de Inicialização e Ativação
- **Inicializador**: `HeNormal()`, adequado para as camadas ReLU.
- **Ativação**: Utiliza principalmente ReLU nas camadas convolucionais e sigmoid na camada de saída.




